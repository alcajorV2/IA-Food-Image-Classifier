{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data.dataloader\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprobamos si se puede usar la gráfica para realizar los procesos más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Si vemos que nos devuelve CPU es o bien porque no tenemos instalado CUDA o pq nuestro dispositivo no lo soporta.\n",
    "Así pues vamos a proceder a instalarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos el dataset (preparamos los datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((128, 128)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    torchvision.traq\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(torchvision.datasets.Food101(r\"D:\\datasets\", split=\"train\", download=True, transform=transform), batch_size=128, shuffle=True, pin_memory=True, num_workers=4),\n",
    "    'test': torch.utils.data.DataLoader(torchvision.datasets.Food101(r\"D:\\datasets\", split=\"test\", transform=transform), batch_size=128, shuffle=True, pin_memory=True, num_workers=4)\n",
    "}\n",
    "\n",
    "dataloader[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos el modelo de nuestra red nueronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
    "        torch.nn.BatchNorm2d(c_out),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(pk, stride=ps)\n",
    "    )\n",
    "\n",
    "class FoodCNN(torch.nn.Module):\n",
    "  def __init__(self, n_channels=3, n_outputs=101):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 64)\n",
    "    self.conv2 = block(64, 128)\n",
    "    self.conv3 = block(128, 256)\n",
    "    self.conv4 = block(256, 512)\n",
    "    self.conv5 = block(512,512)\n",
    "    self.fc1 = torch.nn.Linear(512*4*4, 512) # Lo cambiamos de 1024 a 512 para probar eficiencia.\n",
    "    self.fc2 = torch.nn.Linear(512, n_outputs)\n",
    "    self.dropout = torch.nn.Dropout(0.7) # Lo augmentamos de 0.5 a 0.6-0.7 para tratar de reducir el sobreajuste.\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.conv5(x)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = self.dropout(self.fc1(x))  # Aplicar Dropout en esta capa\n",
    "    x = self.fc2(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler, epochs=1, start_epoch=1):\n",
    "    model.to(device)\n",
    "    scaler = torch.amp.GradScaler(device='cuda')\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs+1):\n",
    "        model.train()\n",
    "        train_loss, train_acc = [], []\n",
    "        bar = tqdm(dataloader['train'], desc=f\"Epoch {epoch}/{epochs} - Training\")\n",
    "\n",
    "        for batch in bar:\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss.append(loss.item())\n",
    "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "            train_acc.append(acc)\n",
    "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
    "        \n",
    "        bar = tqdm(dataloader['test'], desc=f\"Epoch {epoch}/{epochs} - Validation\")\n",
    "        val_loss, val_acc = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                X, y = batch\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                val_loss.append(loss.item())\n",
    "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "                val_acc.append(acc)\n",
    "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
    "        \n",
    "        # Scheduler step\n",
    "        mean_val_loss = np.mean(val_loss)\n",
    "        mean_val_acc = np.mean(val_acc)\n",
    "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {mean_val_loss:.5f} acc {np.mean(train_acc):.5f} val_acc {mean_val_acc:.5f}\")\n",
    "\n",
    "        # Llamada correcta al scheduler con la métrica `mean_val_loss`\n",
    "        scheduler.step(mean_val_loss)\n",
    "\n",
    "        # print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FoodCNN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4) # Probamos con SGD en vez de Adam\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)  # Reducción de LR cada 3 épocas\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "\n",
    "# 3. Continuar Entrenamiento\n",
    "# Ajusta la función de entrenamiento para usar `start_epoch`\n",
    "start_epoch, additional_epochs = 1, 2  # La siguiente época después de las 7 completadas = 8\n",
    "# additional_epochs = 1  # Número de épocas adicionales\n",
    "total_epochs = start_epoch + additional_epochs - 1\n",
    "\n",
    "# Ejecutar entrenamiento desde la época 8 hasta la 17\n",
    "train(model, dataloader, optimizer, scheduler, epochs=total_epochs, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos el estado actual del modelo (opcional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"C:\\...\\checkpoints\\checkpoint_29_10_24_v5.pt\"\n",
    "torch.save({\n",
    "    'epoch': total_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict()\n",
    "}, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos modelo (opcional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"C:\\...\\checkpoints\\checkpoint_29_10_24_v5.pt\"\n",
    "model = FoodCNN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4) # Probamos con SGD en vez de Adam\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)  # Reducción de LR cada 3 épocas\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "checkpoint = torch.load(PATH, map_location=device, weights_only=True)  # Usa weights_only para mayor segurida. Asegura que los parámetros se carguen en `cuda`\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "num_epochs = checkpoint[\"epoch\"]\n",
    "print(f\"Estructura del modelo: \\n\\n{model.eval()}\")\n",
    "print(f\"Estructura del checkpoint: \\n\\n{checkpoint.keys()}\")\n",
    "print(f\"Número de epochs: {num_epochs}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos que no ha sufrido ninguna alteración la copia (opcional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    bar = tqdm(dataloader['test'])\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        for batch in bar:\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = model(X)\n",
    "            acc.append((y == torch.argmax(y_hat, axis=1)).sum().item() / len(y))\n",
    "            bar.set_description(f\"val_acc {np.mean(acc):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proseguir con el entrenamiento, desde un checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"D:\\...\\checkpoint_29_10_24_v5.pt\"\n",
    "\n",
    "# 1. Inicializar el modelo y otros componentes\n",
    "model = FoodCNN().to(device)  # Mueve el modelo a `cuda`\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# 2. Cargar el checkpoint\n",
    "checkpoint = torch.load(PATH, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "start_epoch = checkpoint[\"epoch\"]  # Aquí simplemente asignamos el valor\n",
    "\n",
    "# Asegurarse de que todos los estados del optimizador estén en `cuda`\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)\n",
    "\n",
    "# 3. Continuar Entrenamiento\n",
    "start_epoch += 1  # La siguiente época después de las completadas\n",
    "additional_epochs = 5\n",
    "total_epochs = start_epoch + additional_epochs - 1\n",
    "\n",
    "# Ejecutar entrenamiento\n",
    "train(model, dataloader, optimizer, scheduler, epochs=total_epochs, start_epoch=start_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del funcionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir las transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar los nombres de las categorías\n",
    "def load_class_names():\n",
    "    with open(r\"D:\\datasets\\food-101\\meta\\classes.txt\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    return classes\n",
    "\n",
    "# Función para predecir la categoría de una imagen y mostrar el porcentaje de certeza\n",
    "def predict_image(image_path, model, device, class_names):\n",
    "    # Cargar la imagen\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Aplicar las transformaciones\n",
    "    transformed_image = transform(image).unsqueeze(0)  # Añadir una dimensión para el batch\n",
    "    \n",
    "    # Mover la imagen al dispositivo (GPU o CPU)\n",
    "    transformed_image = transformed_image.to(device)\n",
    "    \n",
    "    # Poner el modelo en modo de evaluación\n",
    "    model.eval()\n",
    "    \n",
    "    # Desactivar el cálculo de gradientes\n",
    "    with torch.no_grad():\n",
    "        # Realizar la predicción\n",
    "        output = model(transformed_image)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)  # Convertir la salida a probabilidades\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    # Obtener la categoría y la certeza de la predicción\n",
    "    predicted_category = class_names[predicted.item()]\n",
    "    confidence_percentage = confidence.item() * 100\n",
    "    \n",
    "    # Mostrar la imagen con la categoría y el porcentaje de certeza\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Categoría predicha: {predicted_category}\\nConfianza: {confidence_percentage:.2f}%')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # También devuelve los resultados en caso de que quieras hacer algo más con ellos\n",
    "    return predicted_category, confidence_percentage\n",
    "\n",
    "# Ejemplo de uso\n",
    "model = FoodCNN()\n",
    "PATH = r\"C:\\...\\checkpoints\\checkpoint_29_10_24_v5.pt\"\n",
    "checkpoint = torch.load(PATH, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Cargar los nombres de las categorías\n",
    "class_names = load_class_names()\n",
    "\n",
    "# Ruta de la imagen de prueba\n",
    "image_path = r\"C:\\...\\images-for-test\\waffles-1.jpeg\"\n",
    "predicted_category, confidence = predict_image(image_path, model, device, class_names)\n",
    "# print(f'La categoría predicha es: {predicted_category} con un {confidence:.2f}% de certeza')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación para la website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requiere de una precarga del modelo.\n",
    "\n",
    "model.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
